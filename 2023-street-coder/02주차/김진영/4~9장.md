# 04. 맛있는 테스트

- 테스트 때문에 고민해서는 안된다. 테스트는 작성하기 가장 쉬운 코드여야 함. 만약 그렇지 않다면 뭔가를 잘못하고 있는 것이다.

- 명확한 목적을 위해 테스트를 작성하라

- 테스트 대상을 의식적으로 찾아서 테스트 수를 줄여라

  - 경계값
  - 중요 비즈니스 로직

- 파레토의 법칙과 같이 테스트 대상을 현명하게 선택하면 20%의 테스트 커버리지로 80%의 신뢰성을 얻을 수 있다.

- 적절한 타입을 사용하면 컴파일러에게 테스트를 위임할 수 있다.

  

# 05. 보람 있는 리팩토링

- 한 번에 너무 큰 변경을 수행하면, 변경하는 동안 같이 일하는 다른 개발자와 자주 충돌하게 될 것이다. 때문에 점진적으로 리펙토링 하라
- 동료의 작업 흐름을 중단하지 않기 위해, 최대한 빨리 작업을 워크플로에 통합할 수 있도록 추구하라

## 리팩토링 각보기

- `구성 요소를 식별하라`
  - 대규모 리팩터링을 하는 가장 좋은 방법은 코드를 의미론적으로 다른 구성 요소로 나누는 것이다.
  - `필요한 변경 사항`과 `다른 개발자와의 충돌 가능성`을 식별하라
  - 컴퓨터 과학의 전체 역사는 엔트로피와의 싸움이다
- `작업량과 위험도를 추정하라`
  - 다른 사람의 작업 흐름을 중단하지 않고 최대한 빨리 작업을 워크플로에 통합할 수 있는 방법을 찾아라
- `대규모 리팩터링을 해야한다면, 인터페이스를 만들고 갈아끼울 수 있도록 하라`
  - 그러면 다른 사람의 작업을 방해하지 않고 충돌을 방지할 수 있다.
- `신뢰할 수 있는 리팩터링의 비결은 테스트이다`

## 리팩토링을 현실적으로 고민하라

지금 상황이 아래 기준 중 하나라도 충족한다면, 리팩토링을 피하거나 최소한 연기하는 것을 고려해야 한다.

일의 우선순위를 결정하는 것은 항상 상대적이고, 바다에는 항상 더 많은 물고기가 있다.

- `리팩토링이 수단이 아닌 목적이 되게 하지 마라`
  - 그것을 통해 얻는 이득에 대해 고려해야한다.
  - 그렇지 않으면 여러분의 시간을 낭비할 뿐만 아니라 여러분이 가져온 모든 변화에 적응해야 하는 팀원의 시간까지도 낭비하는 것이다.
- `리팩토링을 하는 유일한 이유가 “이것이 더 우아한가”라면 이것은 커다란 위험 신호다`
  - 우아하다는 것은 주관적일 뿐만 아니라 모호하고 의미가 없다.
  - 확실한 이점이 담긴 리팩토링의 이유를 생각해 내도록 노력하라.
- `나중에 쉽게 이동하거나 리팩토링할 수 있는 경우는 좀 더 확실한 개선 방안이 떠오를 때까지 미루는 것이 좋다`
  - 대상의 구성 요소가 최소한의 구성 요소 집합에 의존하는가? 이는 나중에 쉽게 이동하거나 리팩토링할 수 있다는 것을 의미한다.
- `테스트가 범위가 아직 부족하다는 건 리팩토링을 피해야 하는 즉각적인 위험 신호`
- `비용을 고려하라`
  - 공통적인 의존 관계인가? 이는 팀원의 작업 흐름을 방해해 팀의 작업 환경에 영향을 미칠 수 있다.
  - 이러한 비용을 보상하기에 여러분이 추구하는 이득이 충분하지 않다면 리팩토링을 뒤로 미루는 것을 고려해야 한다.

# 06. 조사를 통한 보안

이 바닥 코더들은 그들의 현재뿐만 아니라 미래까지도 최적화한다.

- 우리의 목표는 인생에서 큰 성공을 거두기 위해 최소한의 일을 하는 것이다.
- 보안과 관련된 결정을 신뢰성에 대한 기술 부채로 보는 것은 전반적으로 우리의 삶을 최적화하는 데 도움이 된다.

## 보안을 염두에 두고 설계하라

- 보안은 나중에 개선하기가 어렵다.
  - 대부분 처음부터 안전하지 않은 설계 결정으로 코드를 작성하기 때문이다.
  - 따라서 초반 설계부터 보안을 고려하는 것이 중요하다.
- `위협 모델을 검토하라.`
  - 지금 보안을 유지하는 데 드는 비용, 나중에 보안을 유지하는 데 드는 비용을 파악하라
- `앱에 필요한 보안 암호를 저장할 위치를 결정하고 암호를 어렵게 만들어라`
- `최소한의 권한을 주도록 설계하라`
- `이 원칙을 조직 전체에 적용하라.`
  - 신뢰의 문제가 아니라 비개발직군도 누구나 접근 권한이 외부의 개인이나 조직에 의해 유출될 수 있다.

## 은둔 보안 방식의 유용성

- 소프트웨어 보안은 시간과의 싸움이다.
- 숨기는 것으로 보안을 이루려는 사람들은 안전도 은둔도 받을 자격이 없다 - 벤자민 프랭클린이 한 말이다.
- 위험한 건 알지만 이를 무시하고 숨기는 은둔 보안은 좋지 않다.

## 캡차는 사용성을 해칠 수 있다

- 캡차는 진짜와 가짜를 분리하기 위해 잘 알려진 방법이지만, 서비스를 이용하는 사용자에게는 큰 장애물이다.
- 캡차의 대체 방안으로 캐시를 공격적으로 사용하며 필요에 따라 스로틀링을 사용하라.

## 필요 없는 데이터는 수집하지 마라

- 처음부터 데이터가 없다면 유출될 일도 없다.
- 서비스 기능에 영향을 준다고 생각되는 데이터가 아니라면, 다른 데이터를 수집하는 것에 적극적으로 반대하라
- 이를 통해 스토리지 요구 사항 감소, 성능 향상, 데이터 관리 작업 감소, 사용자의 마찰 감소와 같은 부수적인 이점을 얻을 수 있다.
  - e.g. 수많은 웹 사이트에서는 회원 가입을 위해 사용자의 실명을 요구한다. 하지만 그 데이터가 정말 필요할까?

## 문자열 비교 시간이 일정하도록 하는 것이 비교적 안전할 수 있다

- 문자열 비교 시간이 일정하도록 하면 해커가 피드백을 받는 시간이 일정하고 적절하게 지연되고 비교적 안전할 수 있다.
  - 해커에게 빠른 피드백 루프를 제공할 필요는 없다.

```go
// 불일치가 발견되면 바로 return.
// 해커가 불일치라는 피드백을 좀 더 빨리 받게되어 더 빠르게 많은 해킹을 시도할 수 있다.
func compareBytes(a []byte, b []byte) bool {
  if len(a) != len(b) {
  return false
  }

  for i := range a {
    if a[i] != b[i] {
    return false
    }
  }

  return true
}

// 이렇게 하면 동일한 시간에 피드백을 받게 됨
func compareBytesSafe(a []byte, b []byte) bool {
  if len(a) != len(b) {
  return false
  }

  success := true
  for i := range a {
  if a[i] != b[i] {
    success = false
  }
  }

  return success
}
```

## 고정된 솔트를 사용하지 마라

- `솔트(salt)`는 원래 동일한 해시 값을 갖는 비밀번호이지만 값에 차이를 주기 위해 암호 해싱 알고리즘에 도입된 추가적인 값이다.
- 따라서 이를 고정된 값으로 사용하는 건 보안을 악화시키는 불필요한 지름길이다
- 암호학적으로 안전한 `의사난수 생성기`(Cryptographically Secure Pseudo Random Number Generator, CSPRNG)를 활용하라
- `UUID는 랜덤이 아니다`
  - 보안적 관련 컨테스트에서 UUID가 아닌 암호학적으로 안전한 의사 난수를 사용하라.

# 07. 자기 주장이 뚜렷한 최적화

- 최적화에 대한 프로그래밍 참고 문헌은 항상 저명한 컴퓨터 과학자 도널드 커누스의 말을 인용하는 것으로 시작한다.
  - **“섣부른 최적화는 모든 악의 근원이다.”** 이 말은 잘못 알려졌을 뿐만 아니라 항상 잘못 인용되고 있다.
  - 1. 모든 악의 근원은 객체 지향 프로그래밍(OOP)이라는 것을 모두가 알고 있으므로 이 말은 잘못된 표현이다.
    - OOP는 나쁜 클래스 구조로 여러 가지 문제를 불러온다.
  - 2. 실제 인용문은 더 미묘하기 때문에 잘못됐다.
    - 다른 의미가 있는 라틴어 텍스트의 중간에서 가져온 말이기 때문에 그 뜻을 정확히 알 수 없다.
    - 커누스가 실제로 한 말은 다음과 같다.
    - **“우리는 작은 효율성을 잊어야 한다. 97%의 경우에 말이다. 섣부른 최적화는 모든 악의 근원이나. 그러나 중요한 3%의 기회를 놓쳐서는 안 된다.”**
- 오히려 이 책의 저자는 섣부른 최적화는 모든 학습의 근원이라고 주장한다.
  - 열정적으로 임하는 일에 주저하지 마라
  - 최적화는 문제를 해결하는 것이고
  - 섣부른 최적화는 존재하지 않는 가상의 문제를 만들어 푸는 것과 같으며 좋은 연습이 되어준다.
  - 배움의 기회를 놓치지 마라
- **하지만 섣부른 최적화를 권하지 않는 데는 다 이유가 있다.**
  - 최적화는 코드에 경직성을 가져와 유지 보수를 어렵게 만들 수 있다.
    - 즉, 최적화는 투자와 같고 투자 수익률은 주로 얼마나 오래 유지할 수 있는 지에 달렸다.
  - 최적화할 때 발생할 수 있는 트레이드오프를 이해해야 한다.

## 올바른 문제를 해결하라

- 느린 성능은 여러 가지 방법으로 수정할 수 있으며, 문제의 정확한 특성에 따라 적절한 솔루션을 결정해야 한다.
- 성능 문제의 진정한 본질을 이해하기 위해 먼저 벤치마킹 등을 통해 지표를 만들고 성능 문제가 있는지를 판단하라.

## 성능 최적화하기

- `하향식으로 성능 병목 지점을 찾아라`
  - 문제의 근본 원인을 이진 탐색으로 효율적으로 찾을 수 있다.
- `불필요한 코드를 제거하라`
  - 중첩 루프를 제거하라
  - 자료형을 활용하라
- `문자열 사용을 지향하라`
  - 타입 캐스팅, 스토리지 오버헤드
- `if 문 안에 연산은 앞에서부터 실행되므로 가장 많이 계산되는 조건문을 앞으로 배치하라.`
- `데이터를 패킹하지 마라`
  - CPU가 정렬되지 않은 메모리 주소에서 데이터를 읽는 경우 패널티가 발생할 수 있다.
  - 보통 컴파일러가 메모리 주소 정렬 작업을 한다.
- `근접성을 활용하라`
  - 캐시와 같이 메모리 위치를 근접하게 둬서 더 빠르게 접근 가능하도록 하라
- `종속 작업을 세분화하라(병렬 처리)`
- `CPU가 잘 예측할 수 있도록 하라`
  - 스택 오버플로 역사상 가장 유명한 질문은 **“왜 정렬되지 않은 배열을 처리하는 것보다 정렬된 배열을 처리하는 것이 더 빠를까”**이다.
  - CPU는 실행 시간을 최적화 하기 위해 실행 코드보다 선제적으로 움직여서 필요하기 전에 미리 준비한다.
    - 이럴 때 CPU가 사용하는 기술을 `분기 예측(branch prediction)` 이라고 한다.
  - CPU는  비교를 실행하기 전에는 그 결과를 알 수 없지만, 분기 예측을 통해 관찰한 내용에 따라 강력하게 추측할 수 있다.
    - 이러한 추측을 바탕으로 예측을 하고 예측에 성공하면 모든 것이 이미 준비된 상태이기 때문에 성능이 향상된다.
    - 그렇기 때문에 랜덤 값이 있는 배열에서 값을 비교하는 연산이 포함된다면, 배열을 처리하는 속도가 느려질 수 있다.
    - 이럴 경우 분기 예측은 완전히 실패하기 때문이다. 정렬된 배열은 CPU가 순서와 분기를 올바르게 예측할 수 있기 때문에 성능이 더 우수하다.
- `SIMD`
  - CPU는 단일 명령어로 여러 데이터에 대한 연산을 동시에 실행할 수 있는 특수한 명령어를 지원하는데, 이를 `SIMD`(단일 명령어 다중 데이터: Single Instruction Multiple Data)라고 한다.
  - SIMD를 지원하는 아키텍처에서 여러 변수에 동일한 연산을 하려는 경우 이를 통해 성능을 크게 향상 시킬 수 있다.
  - 작업이 계산 집약적이고 여러 요소에 동일한 연산을 동시에 수행해야 할 경우 SIMD를 고려해 보자.
    - C#에서는 Vector 타입으로 SIMD기능을 제공한다.
  - 참고로 SIMD 기반 코드는 책에서 나오는 벤치마크 기준으로 일반 코드보다 2배 빠르다
- `I/O 작업에서 적절한 버퍼 크기를 선정하라`
  - 보통 일정 크기까지 성능이 향상된다
- `I/O 작업을 논블로킹으로 만들어라(비동기)`
- `캐시를 이용하라`
  - 캐싱 무효화는 어려운 문제일 수 있지만 무효화에 대한 걱정하지 않는 것만 캐시하면 문제가 되지 않는다.
  - redis와 같은 정교한 캐싱 레이어도 필요 없고 인메모리 캐시를 사용할 수도 있다.
  - 단, 캐싱을 위해 설계되지 않은 데이터 구조는 사용하지 마라.
    - 이는 보통 오래된 데이터를 제거하거나 만료하는 메커니즘이 없기 때문에 메모리 누수의 원인이 되고, 결국에는 충돌하게 된다.
    - 그러니 캐싱을 위해 설계된 것을 사용하라.
  - 데이터베이스는 훌륭하고 영구적인 캐시가 될 수도 있다.
  - 캐시 만료 시간이 무한대인 것을 두려워하지 마라. 결국에는 지구 멸망으로 캐시가 제거되거나 애플리케이션 재시작이 이뤄질 것이다.

# 08. 기분 좋은 확장성

확장할 수 있는 코드를 만들기 위한 첫 번째 단계는 확장성을 방해하는 잘못된 코드를 제거하는 것이다.

- 잘못된 코드가 병목 현상을 일으켜 하드웨어 리소스를 추가하더라도 코드 속도가 느려질 수 있다.
- 이런 코드 중 일부를 제거하는 것은 직관적이지 않은 것처럼 보일 수도 있다.
- 이러한 잠재적인 병목 현상과 이를 제거하는 방법을 살펴보자

## 잠금(lock)이 정말 필요한지 확인하라

잠금은 경쟁 조건(race condition)을 해결하기 위한 방법 중 하나지만, 이는 잘못하면 교착 상태를 유발하고 무한 대기 상태가 될 수 있다.

- 따라서 잠금이 정말 필요한지 확인하라
- 사용하는 공유 데이터 구조에 잠금이 없어도 되는 대안이 있는지 확인하라
  - array index를 활용하거나 일부 플랫폼의 동시성 대응이 되는 map을 활용
  - 순수 함수

## 불일치를 수용하라

- 신뢰성은 흑백의 개념처럼 이분법적인 게 아니다.
  - 성능과 확장성이 크게 향상된다면 견딜 수 있는 수준의 비신뢰성이 있다.
  - NoSQL은 전톡적인 RDB에서 추구하는 일관성을 무시하는 대신 성능, 확장성, 은닉성을 얻겠다는 철학에서 등장했다.
  - 이러한 접근 방식의 장점을 얻기 위해 NoSQL을 사용할 필요는 없다. MySQL과 같은 기존 RDB에서도 비슷한 이점을 얻을 수 있다.
- `결과적 일관성(eventual consistency)`

## 데이터베이스 연결을 캐시하지 마라

- 보통 커넥션 풀이라는 객체에 DB connection을 모아두고 사용할 텐데
open, close 까지의 과정을 request의 한 작업 단위로 캐싱하여 묶으면, 다른 request가 해당 DB Connection이 반환될 때 까지 대기해야한다.
- 이 방법 대신에 각 쿼리 하나의 수명 동안에만 활성화되고 사용되지 않을 때는 다른 요청에서 사용할 수 있도록 하라
  - 이렇게하면 쿼리 하나 동안만 커넥션 풀에서 connection을 꺼내 사용하므로 더 많은 request를 받을 수 있고 확장성이 늘어난다.

## 스레드를 남용하지 마라

- `스레드(Thread)` 는 CPU 코어 당 하나씩 실행된다.
- 운영 체제(OS)가 선점형 스케줄링 등을 활용해 스레드를 CPU 코어에 적절하게 배치해서 보통 일반적인 경우 사용자는 스레드가 단일 CPU에서 번갈아 실행된다는 사실을 눈치채지 못한다.
- OS가 스레드를 스케줄링하는 방법 때문에 스레드 풀에 CPU코어 수보다 더 많은 스레드를 두어 단순하게 활용성을 높일 수 있지만 사실 이는 실제로 확장성을 해칠 수 있다.
  - 실제로 스레드가 엄청 많아진다면 모든 스레드가 CPU 시간보다 작은 실행 시간을 얻게 되고 결국 실행 시간이 더 오래 걸려 API 응답이 엄청나게 느려진다.
- I/O 대기 시간을 활용하는 더 정확한 방법은 비동기 I/O를 활용하는 것이다.
  - await 키워드를 통해 비동기 동작 여부를 명시적으로 표현할 수 있다.

## 비동기 코드의 주의사항

- I/O 작업이 없다면 비동기도 필요 없다
- 동기화와 비동기화를 섞지 마라
  - 동기화된 컨텍스트에서 비동기 함수를 안전하게 호출하는 것은 매우 어렵다.
  - 동기화 코드에서 비동기 함수를 기다리는 것은 비동기 함수 안에 존재하는 다른 함수로 데드락이 발생할 수 있으니 주의해야 한다.

## 모놀리스를 존중하라

- 마이크로서비스 아키텍처는 단점보다 장점이 클 때만 사용할 것을 고려하라
- 모놀리스로도 20년 이상 MAU 4천만명을 대상으로 서비스를 제공할 수 있다.

# 09. 버그와의 동거

- 버그가 없는 프로그램을 만들기란 불가능하다.
- 소프트웨어 개발에 착수하기 전에 먼저 이 사실을 받아들이는 것이 여러분의 일을 더 쉽게 만들 것이다.

## 버그에 우선순위를 파악하라

- `적용` 가능성, `영향`, `심각성`  같은 유형의 지표로 버그의 우선순위를 판단하라.
- 우선순위와 심각성에 대한 임계 값을 설정하고 순위가 그 아래인 버그들은 고치지 않는 판단을 할 수도 있어야한다.
  - 왜냐하면 항상 다른 중요한 일들이 존재하기 때문이다.
  - 버그를 추적하는 것도 비용이다.
  - 여기가 전쟁터라면 제한된 자원을 적절히 할당해야한다.

## try catch를 했으면 에러를 무시하지 마라

- 에러를 무시하는 경우 실제 의도치 않은 에러가 발생한 경우 추적하기 어렵다.
- try/catch 가 코드 충돌을 위한 빠르고 쉬운 패치이긴 하지만 이는 근본적인 원인을 해결하진 못한다.

## 예외 복원성

- 코드에 충돌이 발생한 경우에도 예외 처리 없이 올바르게 동작해야 한다.
- 예외가 계속 발생하더라도 잘 작동하는 흐름을 설계해야 하며, 이로 인해 다른 코드가 오염된 상태를 가져선 안된다.
- 예외는 어차피 발생하기 때문에 설계상 코드는 이를 견딜 수 있어야 한다.
- 예외 복원성이 뛰어난 설계는 `멱등성`에서 시작한다.
  - 함수를 몇 번 호출하든 상관없이 예외가 계속 발생한다면 우리는 이게 정말 문제가 있다는 사실을 명확하게 알 수 있다.
  - 반대로 코드를 문제없이 여러 번 안전하게 호출할 수도 있다는 뜻도 된다.
  - update 쿼리에서 where 조건에 id뿐만 아니라 현재 상태를 같이 두어서 멱등성을 보장할 수도 있다.
  - `트랜잭션`도 같은 맥락에서 예외 복원성에 도움이 된다.
- `예를 들어 앨범 DB 데이터와 외부 이미지 업로드 API call을 한다고 하면 트랜잭션을 사용할 수 없는데,
  이때는 다음과 같은 방법이 있다`
  - 1. 임시 위치에 이미지 폴더를 먼저 만들고 이미지를 올린 뒤 앨범 DB 데이터를 저장한다.
    - 이러면 이미지 업로드는 성공하더라도 앨범 DB 데이터가 없으므로 사용자 입장에선 미완성도니 앨범 데이터를 볼 일이 없다.
  - 2. 앨범 DB 데이터를 비활성화 상태로 먼저 저장하고 추가 이미지 등 다른 데이터를 모두 저장 후 활성화 상태로 변경한다.
    - 이렇게하면 업로드 프로세스가 중단되더라도 앨범 DB 데이터가 중복될 일은 없다.
  - **두 가지 경우 주기적으로 작업이 중단된 레코드를 정리하는 job을 만들 수도 있다.**
  - 즉, 최종적 일관성만 보장되면 상관없다.
- `오류가 일반적이거나 예상되는 경우에는 예외 대신 결과 반환 코드나 enum을 사용하는 것도 방법이다`
  - 예외 발생 시 스택을 조사해야하므로 단순히 반환 코드를 활용하는 것이 좀 더 저렴할 수 있다.





- 거대한 코드가 딱딱하게 굳어 버리면 어떻게 하지?

- timestimp 포함이 되어 있어도 hashing avalanche effect가 되면 의미가 없지않나?

- rds pk clustering 되면 메모리 파편화에 대한 걱정이 없지 않나?
- r2dbc vs jdbc 
- redis에 의존성이 높아질 수록 rdb 최적화를 너무 일찍 포기하는 것은 아닐지
- MSA와 확장성이 coreaction이 동치일까?
