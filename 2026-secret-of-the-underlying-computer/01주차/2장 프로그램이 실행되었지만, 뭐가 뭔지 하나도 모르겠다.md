```toc
```

## 운영체제, 프로세스, 스레드의 근본 이해하기

CPU는 프로세스, 스레드 등을 모름. 그냥 명령어 가져와서 실행할 뿐
그러면 어떤 기준으로 명령어를 가져오는가? PC(Program Counter) 레지스터에서 가져옴
PC에는 다음에 실행할 메모리에 저장된 명령어 주소가 저장되어 있음

그렇다면 PC는 누가 설정하나?
PC 주소는 기본적으로 자동으로 1씩 증가. 보통 그렇게 순차적으로 실행하므로
단, if 함수 호출 등이 발생하면 PC 레지스터 값을 동적으로 변경

그렇다면 최초에는 어떻게 설정?
프로그램을 실행하면 main 함수에 대응하는 첫 번째 기계 명령어를 찾고 그 주소를 PC에 저장


단, 여전히 다음 작업이 필요
- 프로그램을 적재할 수 있는 적절한 크기의 메모리 영역 찾기
- CPU 레지스터 초기화, 함수의 진입 포인트 찾아서 PC 레지스터 설정

또한 OS 없이 수동으로 하면 아래와 같은 단점 존재
- 한 번에 한 프로그램만 실행 가능
- OS 없이 수동으로 각종 드라이버 연결 필요
- 또한 각종 라이브러리 함수 또한 직접 구현
- UI도 직접 개발

과거에는 다 이랬다


여러 개의 프로그램을 동시에 실행하려면 번갈아가면서 실행
중지했다가 다시 실행하기 위해서는 상태 저장이 필요 -> `context`

실행 중인 프로그램은 필요한 정보를 기록하기 시작 -> 프로세스라는 구조체 탄생
적재 도구, 멀티태스킹 지원, 각종 라이브러리 등을 구현한 하나의 프로그램 탄생 -> OS


동시에 실행하고 싶다면 여러 개의 프로세스를 만들고, 서로 통신하면 됨
-> IPC(Inter Process Communication)
이런 걸 다중 프로세스 프로그래밍이라고 함
그러나 아래 단점
- 프로세스 생성 오버헤드
- 프로세스마다 자체 주소 공간을 가져 IPC 구현이 어려움

메모리 공간을 공유하면서 여러 개의 실행 흐름만 가질 수 있지 않을까?
-> 스레드

스레드는 주소 공간을 공유하고, 생성 속도도 훨씬 빠르므로 경량 프로세스(lightweight process)라고도 불림

스레드는 주소 공간을 공유하므로 편리하지만, 상호 배제, 동기화 등으로 공유 리소스 문제를 해결해야 함

![](files/Pasted%20image%2020260218201233.png)

함수 실행에는 매개변수, 지역 변수, 반환주소 등이 있다.
이런 정보는 스택 프레임에 저장되고, 모든 함수는 실행 시에 자신만의 런타임 스택 프레임을 가진다.
함수가 호출되고 반환될 때마다 이 스택 프레임은 LIFO로 증가하거나 감소한다.

스레드가 생기면서 실행 흐름도 여러 개 존재하고, 스택 영역도 여러 개가 필요해짐


스레드가 처리하는 작업에는 오랫동안 실행되는 작업과 짧은 시간 동안 실행되는 작업이 있다.
후자는 서버의 요청 처리 등
매번 스레드를 생성하고 종료하면 스레드로 인한 오버헤드가 생긴다.
그래서 나오는 게 스레드 풀 -> 스레드를 재사용

![](files/Pasted%20image%2020260218201347.png)

그렇다면 스레드 풀의 스레드 수는 얼마나?
CPU 집약 vs IO 집약
전자라면 CPU 코어 수와 동일하면 충분할 수도
IO 위주라면 WT(Wait Time)이라는 입출력 대기 시간과 CT(Computing Time)라는 CPU 연산에 필요한 시간으로
`N * (1 + WT / CT)`가 적절. WT, CT 동일하다면 2N개의 스레드 필요
이론적인 값이므로 실제로는 테스트 해보면서 설정하기

## 스레드 간 공유되는 프로세스 리소스

프로세스와 스레드의 차이는?
보통 '프로세스는 운영 체제가 리소스를 할당하는 기본 단위이고, 스레드는 스케줄링의 기본 단위이며, 프로세스 리소스는 스레드 간 공유된다'라고 외우곤 한다.
그렇다면 스레드 간 공유하는 프로세스 리소스는 뭐고, 공유 리소스는 뭐고, 어떻게 작동하나?
반대로 스레드 전용 리소스는 뭔가?

![](files/Pasted%20image%2020260218202024.png)

상태 변화 관점에서 보면 스레드는 사실 함수 실행이다. 스레드라는 이름을 붙였을 뿐
함수 실행에는 어떤 정보가 존재?
이는 스택 프레임에 저장됨
반환값, 매개변수, 지역 변수, 레지스터 등

![](files/Pasted%20image%2020260218202043.png)

스레드는 각자 스택 영역을 지니므로 스레드가 여러 개면 여러 개의 스택 영역 존재

그 외에도 PC 레지스터, 스택 상단 위치를 저장하는 스택 포인터 등 CPU가 명령어 실행할 때 필요한 내부 레지스터도 현재 실행 상태에 속한다
레지스터 정보도 스레드 전용으로, 다른 스레드는 이런 레지스터 정보에 접근 불가능

이런 정보를 통틀어 thread context라고 함

![](files/Pasted%20image%2020260218202133.png)

스레드는 프로세스 주소 공간에서 스택을 제외하고 나머지를 모두 공유

코드 영역은 스레드 간에 공유되므로 특정 함수는 특정 스레드에서만 실행되고 이런 건 불가능
단, 코드 영역은 읽기 전용임
따라서 코드 영역에서는 thread safety issue가 발생하지 않음


데이터 영역에는 전역 변수가 저장됨
이는 공유됨


힙 영역은 동적으로 할당된 메모리
이 또한 공유 리소스


스택 영역은 스레드 전용 공간이지만 실제 구현 측면에서 보면 엄밀하게 격리된 스레드 전용 공간은 아님
프로세스 주소 공간은 가상 메모리 시스템이 특별한 경우를 제외하고, 다른 프로세스의 주소 공간에 접근하지 못하도록 보장함
스택 영역에는 이런 보호가 없음
이는 매우 편리할 수도 있지만 매우 어려운 버그로 이어질 수도 있다


![](files/Pasted%20image%2020260218222054.png)

동적 링크는 런타임에 코드와 데이터가 포함된다
이건 어디에 추가될까?
스택, 힙 영역 사이에 배치된다.
이 또한 공유 영역이다.

마지막으로 연 파일 정보도 프로세스 주소 공간에 저장된다
연 파일은 모든 스레드에서 사용할 수 있으며, 이 또한 스레드 간 공유 리소스에 속한다.



thread local storage라는 것도 있다
스레드 전용 변수로, 모든 스레드가 동일한 변수에 접근하는 것처럼 보이지만 실제 변수의 인스턴스는 각 스레드에 속한다
따라서 스레드가 자신만의 고유한 변수를 지닐 수 있다.

## 스레드 안전 코드는 도대체 어떻게 작성해야 할까?

thread safety : 코드가 스레드 몇 개에서 호출되든, 어떤 순서로 호출되든에 상관없이 올바른 결과가 나오는 것

스레드 안전한 코드를 작성하는 법
- 전역 리소스를 쓰는 경우 스레드 전용 저장소를 쓸 수 있는지 확인.
- 혹은 전역 리소스를 읽기 전용으로 사용할 수 있는지 확인
- 혹은 변수에 대해 atomic operation 적용
- 또는 한 번에 하나의 스레드만 공유 리소스에 접근할 수 있도록 mutex, lock 등을 적용

여기서 말하는 스레드는 기본적으로 커널 스레드를 의미한다
스레드의 생성, 스케줄링, 종료 등을 운영체제가 수행해 프로그래머가 스케줄링에 관여할 수 없는 것

## 프로그래머는 코루틴을 어떻게 이해해야 할까?

코루틴에는 스레드와 유사한 일시 중지, 재개 기능이 있다.

![](files/Pasted%20image%2020260218223515.png)

사실 스레드도 비슷하다.
OS는 코드의 모든 부분에서 프로그램을 일시 중지할 수 있다
컴퓨터 시스템은 주기적으로 timer interrupt를 생성하고, 인터럽트가 처리될 때마다 OS는 현재 스레드의 일시 중지 여부를 결정할 기회를 가진다
덕분에 프로그래머가 언제 스레드를 중지하고, 언제 리소스를 반납할지 결정할 필요가 없음
단, user mode에서는 이런 타이머 인터럽트가 없으므로 `yield` 등으로 어디에서 일시 중지하고 리소스를 반납할 것인지 명시적으로 지정해야 함


코루틴의 개념은 1958년도에 존재했고, 1972년에 Simula 67, Scheme 등에서 구현되었다.
과거에는 스레드가 없었으므로 동시성 프로그램 작성하려면 어쩔 수 없이 이와 같은 기술이 필요했음
그러나 스레드가 등장하고, OS가 동시 실행을 지원하기 시작하면서 코루틴이 잊힘

다시 높은 성능과 동시성을 요구하기 시작하면서 코루틴이 대세가 되기 시작함

![](files/Pasted%20image%2020260218223859.png)

코루틴 구현은 스레드 구현과 본질적으로 차이가 없음
일시 중지 시 상태 정보 기록이 필요함
CPU 레지스터 정보, 함수 실행 시 상태 정보 등이 포함됨
이는 주로 함수의 스택 프레임에 저장됨

![](files/Pasted%20image%2020260218223934.png)

그렇다면 프로세스의 스택 영역은 스레드를 위한 공간인데 코루틴을 위한 스택 프레임 정보는 어디에 저장?
힙 영역에 저장할 수 있다.
힙에 저장하니 메모리만 충분하면 코루틴 개수에 제한이 없고, 코루틴 간 전환이나 스케줄링도 user mode에서 일어나 훨씬 가볍고 효율성도 높다. context 정보 사이즈도 작음

프로세스의 스택 영역은 일반 함수를 위한 것이고, 힙 영역의 코루틴 스택 영역은 코루틴을 위한 것


코루틴이 필요한 이유는 동기 방식으로 비동기 프로그래밍을 가능하게 한다는 것

## 콜백 함수를 철저하게 이해한다

콜백 함수의 본질은 다음과 같다
> 우리는 어떤 일을 해야 하는지는 알지만, 이 일을 언제 하게 될지는 정확히 알 수 없습니다. 반면에 다른 모듈은 언제 해야 할지는 알지만 무엇을 해야 하는지는 모르기 때문에 우리가 알고 있는 정보를 콜백 함수에 잘 담아 다른 모듈에 전달해야 합니다.


콜백 유형에는 두 가지가 있다

![](files/Pasted%20image%2020260219123714.png)

동기 콜백은 가장 익숙한 콜백 유형으로, 블로킹 콜백이라고도 한다.

![](files/Pasted%20image%2020260219123724.png)

함수의 호출이 즉시 완료되고, 콜백 함수와 주 함수가 동시에 실행될 수 있다.
이를 비동기 콜백이라고 하며, 지연 콜백(deferred callback)이라고도 한다.

이는 동시성을 더 잘 활용하므로 입출력 작업 등에서 자주 볼 수 있다.
다만, 비동기 콜백에도 문제가 있다.


비동기 콜백으로 처리하면 callback hell에 빠질 가능성이 높다.

동기식으로는 아래처럼 짤 수 있지만

```
a = GetServiceA();
b = GetServiceB(a);
c = GetServiceC(b);
d = GetServiceD(c);
```

비동기로 짜면 이렇게 된다.

```
GetServiceA(function(a)
    {
        GetServiceB(a, function(b)
            {
                GetServiceC(b, function(c)
                    {
                        GetServiceD(c, function(d)
                            {
                                ...
                            }
                        );
                    }
                );
            }
        );
    }
);
```

그렇다면 비동기 콜백의 효율성을 가지면서 동기 콜백의 가독성을 얻을 수는 없을까?
바로 코루틴

## 동기와 비동기를 철저하게 이해한다

![](files/Pasted%20image%2020260219124422.png)

일반적으로 동기 호출은 동일한 스레드에서 실행
다만 특수한 상황이 하나 있는데, 바로 입출력 작업

![](files/Pasted%20image%2020260219124442.png)

이 또한 동기 호출이지만, 실제로는 system call을 보내므로 운영체제는 호출 스레드를 일시 중지하고, 커널에서 디스크를 읽어 오면 중지된 스레드가 다시 깨어난다
이를 blocking IO라고 한다.

즉, 동기 호출은 호출자와 스레드가 같은 스레드에서 실행 중인지 여부와는 관련이 없다.

![](files/Pasted%20image%2020260219124539.png)

반대로 비동기 입출력은 블로킹되지 않는다.

그렇다면 비동기 호출은 IO가 완료된 시점을 어떻게 알 수 있을까?

두 가지 상황이 있다.
1. 호출자가 실행 결과를 전혀 신경쓰지 않을 때
2. 호출자가 실행 결과를 반드시 알아야 할 때

![](files/Pasted%20image%2020260219124647.png)

1번 상황을 위해서는 콜백 함수를 쓸 수 있다.

2번 상황을 구현하는 방법 중 하나는 notification 작동 방식을 사용하는 것
작업이 완료되면 작업 완료를 알리는 신호나 메시지를 보내는 것
결과 처리는 호출 스레드에서 한다.

![](files/Pasted%20image%2020260219124725.png)

## 아 맞다! 블로킹과 논블로킹도 있다

![](files/Pasted%20image%2020260219143722.png)

동기란 서로가 강하게 결합된 것. 작업 A가 작업 B에 의존하는 등

제약 없이 각자 자신의 작업을 수행할 수 있다면 비동기

![](files/Pasted%20image%2020260219143852.png)

함수를 호출했을 때 실행 중인 스레드나 프로세스를 일시 중지시킨다면 호출 방식이 블로킹인 것

대부분의 블로킹은 입출력이랑 관련있음

![](files/Pasted%20image%2020260219144052.png)

논블로킹이 반드시 비동기를 의미하지는 않음

동기 호출이라고 반드시 블로킹은 아니지만, 블로킹 호출은 확실한 동기 호출임

![](files/Pasted%20image%2020260219144151.png)

위 코드는 `recv` 함수는 논블로킹이지만 전체적인 관점에서 보면 코드는 동기임

즉, 논블로킹이라고 항상 동기는 아님

## 높은 동시성과 고성능을 갖춘 서버 구현

처음에는 다중 프로세스 기술이 등장함
`fork`로 여러 자식 프로세스를 생성할 수 있음
부모 프로세스가 요청을 수신하고, 자식 프로세스가 이를 처리
즉, `process per connection`

![](files/CleanShot%202026-02-20%20at%2019.22.54@2x.png)

이 방식의 장점
- 프로그래밍이 간단해서 이해하기 쉬움
- 프로세스 간 격리가 되므로 한 프로세스에 문제가 생겨도 다른 프로세스에는 영향을 미치지 않음
- 다중 코어 리소스를 최대로 활용할 수 있음

단점
- 주소 공간이 격리되어있어, IPC가 어렵다
- 프로세스 생성 부담이 상대적으로 크다

생성 부담도 줄이고, IPC 부담도 줄이는 게 스레드다.
주소 공간을 공유하므로 별도의 통신 작동 방식을 사용할 필요가 없다

![](files/CleanShot%202026-02-20%20at%2019.24.39@2x.png)

`thread per connection`

다만 주소 공간을 공유하니까 한 스레드에 문제가 생기면 전체가 강제 종료되기도 하고, 공유 데이터 관리를 잘 해야한다.

그래도 프로세스보다 훨씬 가볍고, 유리해서 자주 쓰인다
단, C10K 문제에 따르면 동시 요청 수가 아주 많으면 다중 스레드만으론 감당하기 어렵다.

또한 스레드가 프로세스보다 부담은 적지만 그래도 부담이 없는 건 아니라서 동시 요청 수가 엄청 많으면 메모리 문제나 context switching 문제 등이 발생할 수도 있다.


또 다른 기법에는 이벤트 기반 프로그래밍이 있다.

크게 두 가지 요소가 있다
- 이벤트 : 보통 입출력과 엮임. 데이터 수신, 파일 읽기, 요청 등
- 이벤트를 처리하는 함수 : 보통 event handler라고 한다.

이벤트가 도착할 때까지 기다렸다가, 이벤트가 도착하면 유형을 확이하고 적절한 이벤트 핸들러를 호출한다.

![](files/CleanShot%202026-02-20%20at%2019.30.33@2x.png)

이벤트는 계속 발생하므로 반복해서 처리하게 되는데 이를 이벤트 루프라고 한다.


여전히 고민해야 하는 문제가 있다

- 이벤트 소스: 함수 하나로 어떻게 여러 이벤트 가져올 수 있을까?
- 이벤트 핸들러가 이벤트 루프에서 실행되어할까?

첫 번째 문제가 바로 IO multiplexing 기술이다.

리눅스, 유닉스는 모든 것이 파일로 취급된다.
실제 파일은 물론 네트워크도 file descriptor로 처리된다.
그렇다면 동시에 여러 fd를 다루려면?

```
recv(fd1, buf1);
recv(fd2, buf2);
recv(fd3, buf3);
recv(fd4, buf4);
```

같은 것도 방법이긴 하지만 이는 비효율적

더 좋은 건 OS에게 저 대신 FD 감시하고 있다가 데이터가 들어오면 알려달라고 하는 것
이를 IO Multiplexing이라고 하고 대표적인 게 **epoll**

```
// epoll 생성
epoll_fd = epoll_create();

// 서술자를 epoll이 처리하도록 지정
Epoll_ctl(epoll_fd, fd1, fd2, fd3, fd4...);

while (1)
{
    int n = epoll_wait(epoll_fd);

    for (i = 0; i < n; i++)
    {
        // 특정 이벤트 처리
    }
}
```

![](files/Pasted%20image%2020260220224949.png)

이벤트 핸들러는 그럼 이벤트 루프와 같은 스레드여야할까?

아래와 같다면
- IO가 없고
- 처리 함수가 간단해서 소요 시간이 매우 짧다면

![](files/Pasted%20image%2020260220225043.png)

동일 스레드에서 실행할 수 있다.

그러나 CPU를 많이 쓴다면? 한 이벤트를 처리하느라 다른 이벤트 처리가 늦어진다


![](files/Pasted%20image%2020260220225140.png)

이럴 땐 다중 스레드의 도움을 얻으면 편하다.

보통 이런 경우 worker thread 여러 개와 이벤트 루프 스레드 하나를 두고 처리한다.
혹은 worker thread pool 구현을 하거나
이런 설계 방법에는 reactor pattern 이라고도 한다.

그렇다면 IO는 어떨까?

논블로킹을 쓰는 경우 어차피 블로킹되지 않으므로 상관없다.
그러나 블로킹 IO를 수행하는 경우 이벤트 루프 자체가 멈춰버리므로 절대 블로킹 호출을 해서는 안된다.
블로킹 IO를 포함한 작업은 별도 스레드에 전달되어야 한다.

![](files/Pasted%20image%2020260220225341.png)

보통 프레임워크가 있으니 사용자는 핸들러 코드만 작성하면 된다.
그런데 핸들러는 블로킹 IO를 호출하면 안 되므로 비동기 콜백을 사용해야 하는데, 이렇게 코드를 구성하면 너무 복잡해진다.

따라서 핸들러 함수를 코루틴에서 실행하게 하면 둘 다 챙길 수 있다.

![](files/Pasted%20image%2020260220225808.png)

![](files/Pasted%20image%2020260220225813.png)


## 컴퓨터 시스템 여행: 데이터, 코드, 콜백, 클로저에서 컨테이너, 가상 머신까지

## C10K Problem

[C10k problem - Wikipedia](https://en.wikipedia.org/wiki/C10k_problem)

한 번에 만 개의 연결을 동시에 처리한다는 것
즉, 많은 동시 연결을 처리하는 어려움과 이를 해결하는 법

## Golang의 기본 HTTP 서버

```go
func (s *Server) Serve(l net.Listener) error {  
  // ...
  ctx := context.WithValue(baseCtx, ServerContextKey, s)  
  for {  
   rw, err := l.Accept()  
   // ...
   c := s.newConn(rw)  
   c.setState(c.rwc, StateNew, runHooks) // before Serve can return  
   go c.serve(connCtx)  
  }  
}
```

```go
func (c *conn) serve(ctx context.Context) {  
  // ...
  for {  
   // ...
   w, err := c.readRequest(ctx)  
   inFlightResponse = w  
   serverHandler{c.server}.ServeHTTP(w, w.req)  
   // ...
   }  
  }  
}
```

결국 일종의 thread per connection 모델
정확히는 코루틴을 활용하는 케이스
덕분에 핸들러에서 동기식 코드를 짜도, 큰 성능 문제가 없다.

보통의 linux는 스레드 당 8MB의 스택 영역을 예약해서 스레드가 늘어나면 메모리가 기하급수적으로 늘어나지만, 고루틴은 2~8KB 정도라 수십만 ~ 수백만 개를 생성해도 메모리 부담이 적음.
물론 스케줄링에 대한 부담이나, GC 문제 등은 존재

그렇다면 스레드 풀을 쓰는 것처럼 고루틴 수를 제한할 수는 없을까?

이걸 구현한 게 `fasthttp` 라이브러리
[GitHub - valyala/fasthttp: Fast HTTP package for Go. Tuned for high performance. Zero memory allocations in hot paths. Up to 10x faster than net/http](https://github.com/valyala/fasthttp)

```go
func (s *Server) Serve(ln net.Listener) error {
    maxWorkersCount := s.getConcurrency()

    wp := &workerPool{
        WorkerFunc:            s.serveConn,    
        MaxWorkersCount:       maxWorkersCount,
        MaxIdleWorkerDuration: s.MaxIdleWorkerDuration,
    }
    wp.Start()

    for {
        c, err := acceptConn(s, ln, &lastPerIPErrorTime)
        if err != nil {
            wp.Stop()
            return err
        }
        s.setState(c, StateNew)
        if !wp.Serve(c) {
            // 너무 많은 요청이 몰려 worker pool이 꽉 차버리면 요청 거절
        }
    }
}
```

```go
func (wp *workerPool) getCh() *workerChan {
    var ch *workerChan
    createWorker := false

    wp.lock.Lock()
    ready := wp.ready
    n := len(ready) - 1
    if n < 0 {
        // idle worker 없으면 만들고
        if wp.workersCount < wp.MaxWorkersCount {
            createWorker = true        // 새로 만들어도 됨
            wp.workersCount++
        }
        // idle worker 없는데 새로 만들 수 없으면 error
    } else {
        // idle worker 스택에서 pop
        ch = ready[n]
        ready[n] = nil
        wp.ready = ready[:n]
    }
    wp.lock.Unlock()

    if ch == nil {
        if !createWorker {
            return nil
        }
        vch := wp.workerChanPool.Get()
        ch = vch.(*workerChan)
        go func() {
            wp.workerFunc(ch)              // 고루틴으로 요청 처리
            wp.workerChanPool.Put(vch)     
        }()
    }
    return ch
}
```

```go
func (wp *workerPool) workerFunc(ch *workerChan) {
    var c net.Conn

    for c = range ch.ch {        // 채널에서 새로 들어오는 요청을 기다리고
        if c == nil {
            break
        }

        if err = wp.WorkerFunc(c); err != nil {
        }

        c.Close()

        // 처리 끝나면 자기 자신을 worker pool에 다시 반납
        if !wp.release(ch) {
            break
        }
    }

    wp.lock.Lock()
    wp.workersCount--
    wp.lock.Unlock()
}
```

요청을 처리하고 응답하는 과정에서 작은 객체들이 반복되어 생성된다
크지는 않지만, 요청이 몰리면 이 또한 메모리 압박 + GC로 이어짐

go http 라이브러리는 그냥 생성하고 GC에 모든 걸 맡기지만
fasthttp는 pool 최대한 활용해서 재사용

```go  
type Server struct {  
    ctxPool        sync.Pool    
    readerPool     sync.Pool    
    writerPool     sync.Pool    
    hijackConnPool sync.Pool}  
```

그 외에도.. 문자열 처리 등을 `string`으로 안 하고 `[]byte`로 처리해서 메모리 복사를 줄이는 등 여러 최적화가 있다~
