# 1. 근접성 서비스

## 문제 이해 및 설계 범위 확정

### 기능 요구 사항

- 사용자 위치와 검색 반경 정보에 매칭되는 사업장 정보 반환
- 사업장 소유주가 사업장 정보를 추가, 삭제, 갱신할 수 있음. 하지만, 그 정보가 실시간으로 반영될 필요는 없음.
- 고객은 사업장의 상세정보를 살펴볼 수 있어야 함.

### 비기능 요구 사항

- 낮은 응답 지연
  - 사용자는 신속하게 검색 가능해야 함
- 데이터 보호
  - 위치 정보는 민감 정보여서 GDPR, CCPA 등의 사생활 보호 법안을 준수해야 함
- 고가용성 및 규모 확장성
  - 인구 밀집 지역에서 이용자가 집중되는 시간에 트래픽이 급증해도 감당할 수 있도록 설계

### 개략적 규모 추정

- DAU : 1억명
- 등록된 사업장 : 2억개
- QPS : 한 사용자가 5번의 검색을 한다고 가정하면, 1억 \* 5 / 10^5 = 5000

## 개략적 설계안 제시 및 동의 구하기

### API 설계

- `GET /v1/search/nearby`

  - 특정 검색 기준에 맞는 사업장 목록 반환
  - 검색 결과는 페이지 단위로 나눠서 반환
  - 파라미터는 위도, 경도, 반경을 포함

- 사업장 관련 API
  - `GET /v1/business/:id`
  - `POST /v1/business`
  - `PUT /v1/business/:id`
  - `DELETE /v1/business/:id`

### 데이터 모델

- 읽기 / 쓰기 비율
  - 읽기가 쓰기보다 빈도가 높을 것임
  - 사업장 검색 및 정보 확인이 사업장 정보 추가, 수정, 삭제보다 빈번할 것이기 때문
- 데이터 스키마
  - business_id 기반으로, 위도와 경도를 포함한 테이블을 설계

### 개략적 설계

- 로드 밸런서
  - 유입 트래픽을 여러 서비스에 분산시킴
- LBS
  - 위치 기반 서비스로, 쓰기 요청이 없는 읽기 요청만 발생하는 서비스
  - QPS가 높고, 무상태 서비스여서 수평적 규모 확장이 쉬움
- 사업장 서비스

  - 사업장 소유주가 사업장 정보를 생성, 갱신, 삭제함. QPS는 높지 않음.
  - 고객이 사업장 정보를 조회할 때, QPS가 높아질 수 있음.

- 데이터베이스 클러스터
  - primary-secondary 형태로 구성
    - 주 데이터베이스는 쓰기 요청을 처리하고, 부 데이터베이스는 읽기 요청만 처리한다.
    - 데이터는 주 데이터베이스에 기록된 다음, 어느 정도의 지연뒤에 부 데이터베이스에 복제되어 복제 지연이 존재할 수 있음
- 사업장 서비스와 LBS의 규모 확장성
  - 두 서비스 모두 무상태 서비스이기 때문에, 요청이 몰리는 시간에 자동으로 서버가 추가되고 몰리지 않는 시간에 삭제되도록 구성할 수 있음.
  - 가용성을 높이기 위해 AZ를 나누어서 구성할 수 있음.

### 주변 사업장 검색 알고리즘

많은 회사에서 레디스 지오해시 혹은 PostGIS 등을 사용함.

이것들의 내부구조보다 방안들을 살펴볼 것임.

- 2차원 검색

  - 주어진 반경으로 그린 원 안에 놓인 사업장을 검색하는 방법

    ```sql
    SELECT business_id, latitude, longitude
    FROM business
    WHERE (latitude BETWEEN {:my_lat} - radius AND {:my_lat} + radius)
    AND (longitude BETWEEN {:my_long} - radius AND {:my_long} + radius)
    ```

  - 간단하지만 테이블을 전부 읽어야하므로 효율적이지 못함

    - 위도, 경도에 대한 index를 만들어도 두 집합의 교집합을 구하는 것은 데이터의 양 때문에 효율적일 수 없음
    - 한 차원의 검색속도만 개선할 수 있기 때문

2차원 데이터를 한 차원에 대응시킬 수 있는 방법을 고려해봐야 함. 그것이 아래의 두가지 방법.

- 균등 격자

  - 지도를 균등한 작은 격자로 나누어서 접근하는 방식
  - 문제점은 사업장 분포가 고르지 못하다는 것
  - 인구 밀집 지역에는 작은 격자를, 그렇지 않은 지역에는 큰 격자를 사용하면 좋을 것임
  - 주어진 격자의 인접 격자를 찾는 방식이 어려울 수 있음

- 지오해시

  - 2차원의 위도 경도 데이터를 1차원의 문자열로 변환하는 방식
  - 비트를 하나씩 늘려가면서 재귀적으로 세계를 더 작은 격자로 분할
  - 전 세계를 자오선과 적도 기준으로 사분면으로 나누고, 그 각 격자들을 또다시 사분면으로 나누어서 특정한 정밀도까지 나누는 방법
  - 최적 정밀도는 사용자가 지정한 반경으로 그린 원을 덮는 최소 크기 격자를 만드는 지오해시 길이를 구해야함.

    - ex) 0.5km가 반경이면 지오해시 길이는 6, 5km가 반경이면 지오해시의 길이는 4

  - 문제점 ( 엣지 케이스 )
    - 격자 가장자리 이슈
      - 지오해시는 보통 공통 접두어가 긴 격자들이 가까이 있음을 보장함.
      - 하지만 그 역은 참이 아님. 아주 가까워도, 적도의 다른쪽에 놓이거나 자오선상 다른 반쪽에 놓이는 경우 공통 접두어가 존재하지 않는 경우가 발생할 수 있음.
    - 격자 가장자리 이슈 2
      - 공통 접두어의 길이가 길지만 서로다른 격자에 존재하는 경우가 존재할 수 있음.
      - 현재 격자를 비롯한 인접한 모든 격자의 정보를 가져오는 방식으로 해결 가능
    - 표시할 사업장이 충분치 않은 경우
      - 현재 격자와 주변 격자를 살펴봤는데 사업장을 충분히 찾지 못한다면?
        - 선택지1 : 그 정보만 반환한다. 간단하지만, 사용자 입장에선 충분하지 못할 수 있음.
        - 선택지2 : 검색 반경을 키운다. 마지막 비트를 삭제하여 얻은 지오해시 값을 사용해 주변 사업장을 검색하는 것. 특정 값을 기준으로 검색 확장을 진행하다 중단하는 방식

- 쿼드 트리

  - 격자의 내용이 특정 기준을 만족할 때까지 재귖거으로 사분면 분할을 하는 방식

    - 예를 들어, 격자에 담긴 사업장수가 100이하가 될 때까지 재귀적으로 분할

      ```kotlin
      fun buildQuadTree(node: TreeNode) {
        if (node.countNumberOfBusiness() > 100) {
          node.subDivide()
          for (child in node.children) {
            buildQuadTree(child)
          }
        }
      }
      ```

  - 쿼드트리를 전부 저장하는데 얼마나 많은 메모리가 필요할까?

    - 말단 노드에 수록되는 데이터
      - 격자 식별에 사용되는 좌상단 우하단 꼭짓점 좌표 : 8byte \* 4
      - 사업장 id 목록 : 8byte \* 100
      - 합계 : 832byte
    - 내부 노드에 수록되는 데이터
      - 격자를 식별하는데 사용될 좌상단 우하단 꼭짓점 좌표 : 8byte \* 4
      - 하위 4개의 노드를 가리킬 포인터 : 8byte \* 4
      - 합계 : 64byte
    - 계산

      - 격자안에는 최대 100개의 사업장
      - 말단 노드의 수 = 200m / 100 = 2m
      - 내부 노드의 수 = 2m \* 1/3 = 0.67m
      - 총 메모리 요구량 = 2m _ 832byte + 0.67m _ 64 = 1.71GB

    - 총 1.71GB 정도의 메모리가 필요하며, 꽤 작다는 것을 알 수 있음
    - 전체 사업장 수를 n이라고 하면, n/100 \* log(n/100) 정도의 시간 복잡도가 걸리며, 200m개 기준으로 몇 분 정도의 시간이 소요됨.

    - 쿼드트리로 주변 사업장을 검색하려면?
      - 메모리에 쿼드트리 인덱스를 구축
      - 검색 시작점이 포함된 말단 노드를 만날 때까지, 트리의 루트 노드부터 탐색. 해당 노드에 100개 사업장이 있는 경우 해당 노드만 반환. 그렇지 않은 경우 인접노드까지 추가.
    - 쿼드트리 운영시 고려사항
      - 슬로우 스타트
      - 갱신 문제

- 구글 S2

  - 힐베르트 곡선이라는 것을 사용하여 1차원 색인화 하는 방안
  - 매우 복잡한 내부구조를 가지고 있음

### 지오해시 vs 쿼드트리

- 지오해시
  - 구현과 사용이 쉽다. 트리 구축이 필요 없다.
  - 지정 반경이내 사업장 검색을 지원한다.
  - 정밀도를 고정하면 격자 크기도 고정된다.
    - 인구 밀도등에 따라 격자 크기를 조정할 수 없다.
  - 색인 갱신이 쉽다. 색인에서 사업장 하나를 삭제하려면 지오해시 값과 사업장 식별자가 같은 열 하나를 제거하기만 하면 된다.
- 쿼드트리
  - 구현하기 까다로움.
  - k번째로 가까운 사업장까지의 목록을 구할 수 있다.
  - 인구 밀도에 따라 격자크기를 동적으로 조정할 수 있다.
  - 지오해시보다 색인 갱신이 까다롭다.
    - 사업장 정보를 삭제하려면 루트부터 말단노드까지 트리를 순회해야한다.

## 상세 설계

### 데이터베이스의 규모 확장성

- 사업장 테이블
  - 샤딩을 적용하기 좋은 후보
  - 사업장 ID를 기준으로 샤딩을 하면 모든 샤드에 고르게 부하를 분산할 수 있음
- 지리 정보 색인 테이블

  - 지오해시를 사용한다면 지오해시에 연결되는 사업장의 아이디를 매핑하는 테이블을 만드는 것이 좋음
  - geohash와 business_id의 list를 사용하는 방법보다, 위 방법이 좋은 이유는?
    - 사업장 정보 갱신시 business_id_list 배열을 읽은 후 갱신할 사업장을 찾는 연산이 필요함. 등록시에도 이미 존재하는지 체크하는 등의 연산이 필요함.
    - 병렬적으로 실행되는 갱신 연산에서 데이터 소실을 막기위해 락을 잡거나해야하는데, 이러한 경계조건이 너무 많음.

- 지리 정보 색인의 규모 확장
  - 색인 정보를 저장하는데 필요한 데이터양은 그리 많지 않아 최신 데이터베이스 한 대로 모두 수용 가능할 수 있음.
  - 하지만 읽기 연산의 빈도가 높다면 서버 한 대의 cpu와 네트워크 대역폭으로는 요청 전부를 감당하지 못할 수도 있음.
  - 보통 샤딩 혹은 읽기전용 복제본을 사용하는데, 지오해시 테이블은 샤딩이 까다롭다. 애플리케이션 계층에서 구현해야하기 때문이다.

### 캐시

- 캐시를 도입할 때는 벤치마킹과 비용분석을 늘 고려하자.
- 캐시 키
  - 사용자 위치의 위도 경도 정보가 가장 직관적이지만, 아주 정확하지 않고 조금만 움직여도 바뀐다는 단점이 있음.
  - 지오해시 값이나 사업장 ID를 키로해서 캐시를 저장하면 이것은 효과적일 수 있음.

### 지역 및 가용성 구역

- 지금까지 살펴본 위치 기반 서비스는 여러 지경과 가용성 구역에 설치한다.
- 사용자와 시스템 사이의 물리적 거리를 줄일 수 있고, 트래픽을 인구에 따라 고르게 분산하는 유연성을 확보할 수 있다.

### 결과 필터링

- 지오해시 혹은 쿼드트리를 통해 얻어온 결과의 양은 상대적으로 적기 때문에, 근처 사업장 정보를 전부 확보한 다음 그 사업장 정보를 전부 추출해서 필터링하면 됨.

### 최종 설계

- 주변 500미터 반경에서 모든 식당을 찾는 경우를 고려해보자
- 로드밸런서에게 클라이언트가 위치와 검색반경을 전송
- 로드밸런서는 LBS에게 요청을 보냄
- 주어진 위치와 반경에 고려하여 LBS는 지오해시의 길이를 계산하고, 500미터에 따른 길이는 6임.
- LBS는 인접한 지오해시를 계산한 다음 목록에 추가
- 지오해시 각각에 대해 LBS는 지오해시 레디스 서버를 호출하여 해당 지오해시에 대응하는 모든 사업장 ID를 추출
- 사업장 ID를 기반으로 사업장 정보를 조회

- 사업장 정보 조회, 갱신, 추가 그리고 삭제
  - 사업장 정보가 갱신, 추가 그리고 삭제될 때 캐시에 실시간으로 반영할 수도 있지만, 밤사이 처리할 수도 있음.

# 2. 주변 친구

근접성 서비스와 다르게 주변 친구 정보는 실시간으로 변경된다는 차이를 일단 이해하자.

## 문제 이해 및 설계 범위 확정

- 지리적으로 5마일 이내를 가깝다고 표현하며, 사용자가 설정할 수 있는 수치여야함.
- 직선거리 기준
- 10억명의 사용자중 10%인 1억명이 해당 기능을 사용중
  - 동시 접속 사용자는 1억명중 10%인 천만명으로 가정
- 이동 이력을 보관해야 함
- 친구 관계에 있는 사용자가 비활성 상태면 주변 친구 목록에서 제거
- 사생활 보호법등은 고려하지 않음
- 친구 위치는 30초 주기로 갱신

  - 사람이 걷는 속도가 시간당 4~5km 정도이기에, 30초 정도 이동한다해서 크게 검색결과가 달라지지 않음.

- 평규적으로 한 사용자는 400명의 친구를 가지며, 그 모두가 주변 친구 검색 기능을 사용한다 가정하자

- QPS = 천만 / 30 = 334,000

## 개략적 설계안 제시 및 동의 구하기

### 개략적 설계안

- 활성화된 모든 친구와 통신 상태 유지하기
  - 통신 연결 상태나 전력이 충분하지 않기에 적절치 않음.
- 공용 백엔드를 사용
  - 모든 활성 상태 사용자의 위치 변화 내역 수신
  - 사용자 위치 변경 내역을 수신할때마다 해당 사용자의 모든 활성 상태 친구를 찾아서 그 친구들의 단말로 변경내역 전송
  - 거리가 특정 임계치보다 먼 경우에는 전송하지 않음
  - 명쾌해보이지만 큰 규모에서 사용하기엔 문제가 있음

### 설계안

소규모를 위한 설계안부터 고려

- 로드 밸런서
- REST API
- 웹소켓 서버
  - 친구 위치 정보 변경을 실시간에 가깝게 처리하는 stateful한 서버 클러스터. 각 클라이언트는 그 가운데 한 대와 웹소켓 연결을 지속적으로 유지
- 레디스 위치 정보 캐시
  - 활성 상태 사용자의 가장 최근 위치 정보를 캐시함
  - TTL이 지나면 해당 사용자는 비활성 상태로 변경되고, 캐시에서 제거됨
- 사용자 데이터베이스
  - 사용자 데이터베이스에는 사용자 및 친구관계 정보를 저장
- 위치 이력 데이터베이스
  - 사용자의 위치 변경 이력을 보관
- 레디스 펍/섭 서버
  - 웹소켓 서버를 통해 위치 정보 변경이벤트를 발행
  - 만약 구독자와 계산한 거리가 검색 반경 이내라면 클라이언트 앱으로 보냄
- 주기적 위치 갱신
  - 모바일 클라이언트는 웹소켓을 통해 주기적으로 우치 변경내역을 전송함
  - 모바일 클라이언트가 로드밸런서에게 위치 변경 내역을 전송
  - 로드밸런서는 변경내역을 해당 클라이언트와 연결된 웹소켓 서버로 전송
  - 웹소켓 서버는 해당 이벤트를 위치 이동 이력 데이터베이스에 저장
  - 웹소켓 서버는 새 위치를 위치 정보 캐시에 보관
  - 웹소켓 서버는 레디스 펍/섭 서버의 해당 사용자 채널에 새 위치를 발행
  - 모든 구독자에게 발행된 이벤트를 브로드캐스트하고, 메시지를 받은 웹소켓 서버는 거리를 계산하여 검색 반경 이내라면 클라이언트에게 보냄

### API 설계

- 웹소켓
  - [서버 API] : 주기적인 위치 정보 갱신
  - [클라이언트 API] : 클라이언트가 갱신된 친구 위치를 수신하는데 사용할 API
  - [서버 API] : 웹소켓 초기화 API
  - [클라이언트 API] : 새 친구 구독 API
  - [클라이언트 API] : 구독해지 API
- HTTP API
  - 친구 추가 / 삭제 혹은 사용자 정보를 갱신하는데 사용하는 API

### 데이터 모델

- 위치 정보 캐시
  - 사용자 ID를 키로하고, { 위도, 경도, 시각 } 을 값으로 갖는 캐시
- 위치 정보 저장에 데이터베이스를 사용하지 않는 이유
  - 사용자의 현재 위치만 필요하기 때문
- 위치 정보 이력
  - 사용자 ID, 위도, 경도, 시각을 저장하는 데이터베이스
  - 보통 카산드라 같은 것을 많이 쓰지만, 관계형 데이터베이스도 사용 가능함 ( 샤딩을 고려해야함 )

## 상세 설계

### 중요 구성요소별 규모 확장성

- API 서버
  - 무상태 서버이기에 오토스케일링등을 고려하면 됨
- 웹소켓 서버
  - 웹소켓 클러스터도 자동으로 늘리는 것은 어렵지 않으나, 유상태 서버이기에 기존 서버를 제거할 때는 주의가 필요함.
  - 웹소켓 노드를 제거하기전 기존 연결을 종료하여 그 서버로는 새로운 연결이 이루어지지 않도록 해야 함.
- 클라이언트 초기화
  - 웹소켓 연결이 초기화되면 클라이언트는 해당 단말의 위치를 전송한다. 그 정보를 받은 웹소켓 핸들러는 다음 작업을 수행한다
    - 위치 정보 캐시에 보관된 사용자의 위치를 갱신
    - 해당 위치는 계산에 사용되기에 변수에 저장하고, 사용자 정보를 가져온다.
    - 위치 정보 캐시에 배치 요청으로 친구 정보를 한 번에 가져온다.
    - 캐시에서 가져온 정보를 기반으로 사용자가 설정한 반경내에 존재하는지 체크하여 클라이언트에 반환
    - 웹소켓 서버는 사용자의 친구의 레디스 서버 펍/섭 채널을 구독하도록하고, 현재 위치를 레디스 펍/섭 서버의 채널을 통해 모든 친구에게 전송한다.
- 사용자 데이터베이스
  - 사용자 정보는 일반적인 데이터
  - 친구관계는 관계형 데이터베이스 서버로는 감당할 수 없을 수 있음. 하지만 사용자 ID 기준으로 샤딩한다면 수평적 규모의 확장은 가능
- 위치 정보 캐시
  - 초당 334k의 갱신 연산을 해야하는데, 고사양 레디스 서버를 쓴다해도 부담이 있을 수 있음.
  - 샤딩을 고려하자.
- 레디스 펍/섭 서버
  - 레디스 펍/섭 서버는 채널을 만드는 비용이 아주 저렴함.
  - 새채널은 구독하려는 채널이 없을 때 생성하고, 구독자가 없는 채널로 전송되는 메시지는 서버에 가해지는 부하가 거의 없다.
  - 얼마나 많은 레디스 펍/섭 서버가 필요한가?
    - 메모리 사용량
      - 주변 친구 기능을 쓰는 모든 사용자에게 채널을 할당하면 1억개고, 활성화 상태 친구 가운데 100명이 주변 친구 기능을 활용한다면 모든 채널을 저장하는데 200GB 정도의 메모리가 필요할 것이다.
      - 100GB의 메모리를 사용하는 레디스 펍/섭 서버를 쓴다면 두 대면 충분하다
    - CPU 사용량
      - 1400만의 초당 업데이트가 온다고 계산했고, 현대 아키텍쳐 기준으로 서버 한대당 10만명의 구독자를 감당할 수 있다고 하면 140대의 서버가 필요
    - 즉 메모리가 아닌 CPU 사용량이 병목이기에 레디스 펍/섭 클러스터가 필요하다
- 분산 레디스 펍/섭 서버 클러스터
  - 모든 채널은 서로 독립적이기 때문에, 메시지를 발행할 사용자 기준으로 펍/섭 서버를 샤딩하면 된다.
  - 안정해시 기반으로 위치 정보 메시지를 발행할 펍/섭 서버를 선정하고 발행한다.
- 레디스 펍/섭 서버 클러스터의 규모 확장 고려사항
  - 펍/섭 서버 채널의 데이터는 무상태라고 할 수 있음.
  - 하지만 펍/섭 서버는 채널에 대한 상태 정보를 보관한다. 구독자 목록이라던지..
    - 특정 채널을 담당하던 펍/섭 서버를 교체하거나 해시 링에서 제거하는 경우, 해당 채널의 모든 구독자에게 그 사실을 알려야 한다.
    - 그렇기에 유상태라고 생각해야 함.
  - 유상태 서버의 규모를 늘리거나 줄이는 것은 운영 부담과 위험이 크기에, 어느 정도 여유를 두고 오버 프로비저닝하는 것이 보통이다.
    - 클러스터 크기를 조정하면 많은 채널이 해시 링위의 다른 여러 서버가 갱신될 수있음
    - 이런 여러 문제 때문에 트래픽이 가장 낮은 시간을 골라서 크기 조정하는 것이 권장됨
- 친구 추가/삭제
  - 친구를 추가하거나 삭제하면 클라이언트는 웹소켓 서버의 연결 핸들러에게 그 사실을 알려야 함. 그래야 새 친구의 채널을 구독할 수 있기 때문
- 친구가 많은 사용자
  - 수 천명의 친구를 구독하는데 필요한 관계는 클러스터 내의 많은 웹소켓 서버에 분산되어 잇을 것임.
  - 핫스팟 문제는 발생하지 않음
- 주변의 임의 사용자
  - 지오해시에 따라 구축된 펍/섭 채널 풀을 두는 방식으로 해결 가능
  - 지오해시 격자로 나눈 다음, 격자마다 채널을 하나씩 만들어 해당 격자내의 모든 사용자가 격자에 할당된 채널을 구독하도록한다.
    - 물론 격자 가장자리 이슈가 있을 수 있으므로, 주변 격자까지 구독하도록 하는 방식도 고려하면 좋다.
- 레디스 펍/섭 외의 대안
  - 얼랭등이 좋은 솔루션이 될 수 있지만, 좋은 프로그래머를 구하기 쉽지 않다
  - 고도로 분산된 병렬 어플리케이션을 위해 고안된 프로그래밍 언어이자 런타임 환경이기 때문
